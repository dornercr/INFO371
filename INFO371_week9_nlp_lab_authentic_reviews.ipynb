{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFkWej85E77blBW+9iPUYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dornercr/INFO371/blob/main/INFO371_week9_nlp_lab_authentic_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFnTQ33V0o3u",
        "outputId": "4104705a-bbf6-4c55-ffe9-420cf34aa29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual tensor: tensor([1, 2, 3])\n",
            "Random 2x3 tensor: tensor([[0.8000, 0.8413, 0.2760],\n",
            "        [0.3816, 0.3965, 0.6991]])\n",
            "Range tensor: tensor([0., 1., 2., 3., 4., 5.])\n",
            "Epoch 1, Batch 0, Loss: 0.6959\n",
            "Epoch 1, Batch 50, Loss: 0.5263\n",
            "Epoch 1, Batch 100, Loss: 0.1796\n",
            "Epoch 1 complete | Total Loss: 51.9886\n",
            "Epoch 2, Batch 0, Loss: 0.0970\n",
            "Epoch 2, Batch 50, Loss: 0.0215\n",
            "Epoch 2, Batch 100, Loss: 0.0106\n",
            "Epoch 2 complete | Total Loss: 3.2379\n",
            "Epoch 3, Batch 0, Loss: 0.0080\n",
            "Epoch 3, Batch 50, Loss: 0.0028\n",
            "Epoch 3, Batch 100, Loss: 0.0023\n",
            "Epoch 3 complete | Total Loss: 0.5730\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    phishing       1.00      1.00      1.00       520\n",
            "       legit       1.00      1.00      1.00       480\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# INFO 371: NLP Lab ‚Äì Retail Dataset (Generated Manually)\n",
        "# Author: Charles Dorner, EdD (Candidate)\n",
        "\n",
        "!pip install torchdata --quiet\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import random\n",
        "\n",
        "# üîß Tensor Demos\n",
        "print(\"Manual tensor:\", torch.tensor([1, 2, 3]))\n",
        "print(\"Random 2x3 tensor:\", torch.rand(2, 3))\n",
        "print(\"Range tensor:\", torch.arange(0, 6, dtype=torch.float32))\n",
        "\n",
        "# üì• Generate Retail Product Reviews Dataset\n",
        "real_reviews = [\n",
        "    \"This charger works perfectly with my iPhone.\",\n",
        "    \"The shoes were comfortable and fit as expected.\",\n",
        "    \"Fast shipping and great customer service.\",\n",
        "    \"The blender is powerful and easy to clean.\",\n",
        "    \"I love the material of this hoodie. Very soft.\",\n",
        "    \"Came exactly as described. Would buy again.\",\n",
        "    \"This laptop case protects well and looks stylish.\",\n",
        "    \"Product matches the description and photos.\",\n",
        "    \"Excellent quality for the price. Very happy.\",\n",
        "    \"These headphones have amazing sound quality.\"\n",
        "]\n",
        "\n",
        "fake_reviews = [\n",
        "    \"Best product ever invented in human history!\",\n",
        "    \"Amazing amazing amazing! Just wow wow wow!\",\n",
        "    \"I bought 50 of these and love every one!\",\n",
        "    \"You won‚Äôt believe how good this is! 100 stars!\",\n",
        "    \"So perfect, I use it 10 times a minute!\",\n",
        "    \"Better than everything else on Earth. Period.\",\n",
        "    \"Five stars because I was told to rate it.\",\n",
        "    \"Unbelievable quality for a penny! Buy now!\",\n",
        "    \"This product made me rich overnight!\",\n",
        "    \"Every household in the galaxy needs one!\"\n",
        "]\n",
        "\n",
        "# Build dataset of 5000 entries (balanced)\n",
        "reviews, sentiments = [], []\n",
        "for _ in range(2500):\n",
        "    reviews.append(random.choice(real_reviews))\n",
        "    sentiments.append(1)\n",
        "    reviews.append(random.choice(fake_reviews))\n",
        "    sentiments.append(0)\n",
        "\n",
        "# Shuffle\n",
        "combined = list(zip(reviews, sentiments))\n",
        "random.shuffle(combined)\n",
        "reviews, sentiments = zip(*combined)\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\"review\": reviews, \"sentiment\": sentiments})\n",
        "\n",
        "# Split manually\n",
        "train_texts = df[\"review\"][:4000]\n",
        "train_labels = df[\"sentiment\"][:4000]\n",
        "test_texts = df[\"review\"][4000:]\n",
        "test_labels = df[\"sentiment\"][4000:]\n",
        "label_names = [\"fake\", \"real\"]\n",
        "\n",
        "# üî† Tokenizer and Vocabulary\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "def yield_tokens(data):\n",
        "    for text in data:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_texts), specials=[\"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<pad>\"])\n",
        "\n",
        "def encode(text):\n",
        "    return torch.tensor(vocab(tokenizer(text)), dtype=torch.long)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    text_list, label_list = [], []\n",
        "    for _text, _label in batch:\n",
        "        text_list.append(encode(_text))\n",
        "        label_list.append(torch.tensor(_label, dtype=torch.long))\n",
        "    text_list = pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
        "    return text_list, torch.stack(label_list)\n",
        "\n",
        "# üì¶ Dataset and DataLoader\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts.iloc[idx], self.labels.iloc[idx]\n",
        "\n",
        "train_ds = TextDataset(train_texts, train_labels)\n",
        "test_ds = TextDataset(test_texts, test_labels)\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# üß† Model Definition\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        mean_emb = embedded.mean(dim=1)\n",
        "        x = self.relu(self.fc1(mean_emb))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ‚öôÔ∏è Training Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TextClassifier(len(vocab), 64, 32, 2).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# üîÅ Training Loop\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch, (X, y) in enumerate(train_dl):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if batch % 50 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch}, Loss: {loss.item():.4f}\")\n",
        "    print(f\"Epoch {epoch+1} complete | Total Loss: {total_loss:.4f}\")\n",
        "\n",
        "# üíæ Save and Reload Model\n",
        "torch.save(model.state_dict(), \"retail_review_model.pt\")\n",
        "model.load_state_dict(torch.load(\"retail_review_model.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# üß™ Evaluation\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dl:\n",
        "        X = X.to(device)\n",
        "        out = model(X)\n",
        "        preds = out.argmax(1).cpu().tolist()\n",
        "        y_true.extend(y.tolist())\n",
        "        y_pred.extend(preds)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=label_names))\n",
        "\n",
        "# üîç Misclassifications\n",
        "for i in range(10):\n",
        "    if y_true[i] != y_pred[i]:\n",
        "        print(f\"‚ùå Predicted {label_names[y_pred[i]]}, Actual {label_names[y_true[i]]}: {test_texts.iloc[i][:100]}\")\n"
      ]
    }
  ]
}