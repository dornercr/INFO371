{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anyuanay/INFO371/blob/main/INFO371_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85Z_qr_HpWBn"
      },
      "source": [
        "# Drexel University\n",
        "## College of Computing and Informatics\n",
        "## INFO 371: Data Mining Applications\n",
        "## Assignment 3\n",
        "\n",
        "## Due Date: Sunday, Feb. 23, 2025\n",
        "### This assignment counts for 15% of the final grade\n",
        "\n",
        "\n",
        "## **DON'T FORGET TO PUT YOUR NAME BELOW**\n",
        "\n",
        "## **NAME:**\n",
        "\n",
        "\n",
        "### A. What to Hand In\n",
        "\n",
        "1. A completed this Jupyter notebook.\n",
        "2. Any data sets used in the assignment.\n",
        "3. Any multimedia and images used in the assignment.\n",
        "\n",
        "### B. How to Hand In\n",
        "\n",
        "Submit your files through the course website in the Blackboard Learn system.\n",
        "\n",
        "### C. When to Hand In\n",
        "\n",
        "1. Submit your assignment no later than 11:59pm in the due date.\n",
        "2. There will be a 10% (absolute value) deduction for each day of lateness, to a maximum of 3 days; assignments will not be accepted beyond that point. Missing work will earn a zero grade.\n",
        "\n",
        "### D. Answer the following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56fbe4nI7qgo"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNggTCN47p-P"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKyoa5MwfWEK"
      },
      "source": [
        "# Import the classifiers: KNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier, and MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Qm7u2Ifh55"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMPxbcS2mceJ"
      },
      "source": [
        "# Import CountVectorizer and TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of1_YQYombdo"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw2Ql_2wgAJh"
      },
      "source": [
        "# Import evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UotG42uOgGra"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWpxEh3wxHsb"
      },
      "source": [
        "# Import the train_test_split function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwopWqouiba6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a14uuvxknZ"
      },
      "source": [
        "# Answer the following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PGFnDU57lOO"
      },
      "source": [
        "## Question 1 [5 points]: Collecting and uploading the movie review data.\n",
        "In this assignment, you will apply various classification models and text vectorizations for sentiment analysis on movie reviews. The original data are from: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews It contains 50K movie reviews. To reduce the size of the data, I have extracted 5K random reviews to this file: `imdb_reviews_5k.csv`. You can work on this small data set in this assignment. Now, upload the 5k reviews and read them in as a DataFrame. Show the columns and size of the data. Display the first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfeZ3UUDbFHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_lTEzhtBL-_"
      },
      "source": [
        "## Question 2 [5 points]: Show the distribution of the sentiment values (positive and negative). Are the values evenly distributed in the data set?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8eN9i0YbFwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGRUiIuoBi3n"
      },
      "source": [
        "## Question 3 [10 points]: You will use the sentiment values as classification labels. Extract the target labels `y` by converting the sentiment values to 1 and 0.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zbXIVnpsbGZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qHxBVO1B8hn"
      },
      "source": [
        "## Question 4 [10 points]: Prepare training and test data sets.\n",
        "Split the review text and target labels into review_train, review_test, y_train, and y_test. Use 80% of the data for taining and 20% for test. Do you need to consider statification when splitting?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oOrwAp97bHXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ny8Wh-Fli8"
      },
      "source": [
        "## Question 5 [50 points]: Classify the sentiment of the reviews using the combinations of various classifiers and vectorizers.\n",
        "In this assignment, you should use the following list of models with default parameters:\n",
        "```\n",
        "models= {'knn': KNeighborsClassifier(), 'dt': DecisionTreeClassifier(), 'rf': RandomForestClassifier(), 'nb':MultinomialNB()}\n",
        "```\n",
        "and the following list of vectorizers:\n",
        "```\n",
        "vectorizers = {'bow_binary':CountVectorizer(ngram_range = (1,1), binary=True), \\\n",
        "               'bow_count': CountVectorizer(ngram_range = (1,1)), \\\n",
        "               'tfidf': TfidfVectorizer()}\n",
        "```\n",
        "The total number of combinations is 12. Compare the performance of the 12 model combinations in terms of `precision`, `recall`, and `f1-measure`. Visualize the performance as illustrated in the following figure:\n",
        "![performance_comparison](https://i.imgur.com/Z4QKCmp.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DExIFQr1bKTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaq7vkRHbhn"
      },
      "source": [
        "## Question 6 [20 points]: Discuss the performance of the various model and vectorizer combinations. Which type of model gave a better performance? Do the vectorization methods affect the performance? Do you have any suggestions on changing the model parameters that could improve the performance? Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7LggfiBqdU4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}